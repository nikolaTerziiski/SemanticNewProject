# app.py
import json
import pathlib
import tempfile

import streamlit as st
from scripts.build_index import run as build_index
from scripts.extract_ontology_forms import run as extract_forms
# This now expects annotate_document to accept 'single_word_threshold'
from scripts.matcher_llm import annotate_document


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Streamlit Page Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(page_title="LLM Ontology Annotator", layout="wide")
st.title("üï∏Ô∏è –û–Ω—Ç–æ–ª–æ–≥–∏—á–µ–Ω –∞–Ω–æ—Ç–∞—Ç–æ—Ä —Å LLM")
st.info("–ö–∞—á–µ—Ç–µ –æ–Ω—Ç–æ–ª–æ–≥–∏—è –∏ —Ç–µ–∫—Å—Ç–æ–≤ —Ñ–∞–π–ª, –∑–∞ –¥–∞ –∑–∞–ø–æ—á–Ω–µ—Ç–µ. –°–∏—Å—Ç–µ–º–∞—Ç–∞ –∏–∑–ø–æ–ª–∑–≤–∞ –ª–æ–∫–∞–ª–µ–Ω LLM —á—Ä–µ–∑ LM Studio –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞.")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1. File Uploads ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
col1, col2 = st.columns(2)
with col1:
    onto_file = st.file_uploader("üìÑ –ö–∞—á–∏ –æ–Ω—Ç–æ–ª–æ–≥–∏—è (.rdf / .owl / .ttl)",
                                 type=["rdf", "owl", "ttl"])
with col2:
    text_file = st.file_uploader("üìù –ö–∞—á–∏ —Ç–µ–∫—Å—Ç (.txt / .md)",
                                 type=["txt", "md"])

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2. Parameters UI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
with st.expander("‚öôÔ∏è –†–∞–∑—à–∏—Ä–µ–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏", expanded=False):
    top_k = st.slider(
        "Top-k –∫–∞–Ω–¥–∏–¥–∞—Ç–∏ (FAISS)", 1, 30, 10,
        help="–ë—Ä–æ—è—Ç –Ω–∞ –Ω–∞–π-–±–ª–∏–∑–∫–∏—Ç–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∏ –æ—Ç –æ–Ω—Ç–æ–ª–æ–≥–∏—è—Ç–∞, –∫–æ–∏—Ç–æ –¥–∞ —Å–µ –ø–æ–¥–∞–¥–∞—Ç –Ω–∞ LLM –∑–∞ –¥–∏—Å–∞–º–±–∏–≥—É–∞—Ü–∏—è."
    )
    # Expose both thresholds for fine-tuning
    default_thresh = st.slider(
        "–ü—Ä–∞–≥ –Ω–∞ —Å—Ö–æ–¥—Å—Ç–≤–æ (–∑–∞ —Ñ—Ä–∞–∑–∏)", 0.0, 1.0, 0.55, 0.05,
        help="–ú–∏–Ω–∏–º–∞–ª–Ω–æ—Ç–æ –∫–æ—Å–∏–Ω—É—Å–æ–≤–æ —Å—Ö–æ–¥—Å—Ç–≤–æ –∑–∞ —Ç–µ—Ä–º–∏–Ω–∏ —Å –ø–æ–≤–µ—á–µ –æ—Ç –µ–¥–Ω–∞ –¥—É–º–∞."
    )
    single_word_thresh = st.slider(
        "–ü—Ä–∞–≥ –Ω–∞ —Å—Ö–æ–¥—Å—Ç–≤–æ (–∑–∞ –µ–¥–∏–Ω–∏—á–Ω–∏ –¥—É–º–∏)", 0.0, 1.0, 0.75, 0.05,
        help="–ü–æ-—Å—Ç—Ä–æ–≥ –ø—Ä–∞–≥ –∑–∞ –µ–¥–∏–Ω–∏—á–Ω–∏ –¥—É–º–∏, –∑–∞ –¥–∞ —Å–µ —Ñ–∏–ª—Ç—Ä–∏—Ä–∞—Ç –æ–±—â–∏ —Ç–µ—Ä–º–∏–Ω–∏ –∫–∞—Ç–æ '–≤–∏–Ω–æ' –∏–ª–∏ '—Ä–µ–≥–∏–æ–Ω'."
    )

run_btn = st.button("üöÄ –ê–Ω–æ—Ç–∏—Ä–∞–π", disabled=not (onto_file and text_file), type="primary")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Helper function for session state ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def ss_get(key, default):
    """Safely get a value from the session state."""
    return st.session_state.setdefault(key, default)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3. Main Pipeline Execution ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if run_btn:
    # Clear previous results
    if "matches" in st.session_state:
        del st.session_state["matches"]

    with st.spinner("–†–∞–±–æ—Ç–∏‚Ä¶ –º–æ–∂–µ –¥–∞ –æ—Ç–Ω–µ–º–µ –¥–æ 1-2 –º–∏–Ω—É—Ç–∏."):
        with tempfile.TemporaryDirectory() as tmpdir_str:
            tmp = pathlib.Path(tmpdir_str)
            ont_path = tmp / onto_file.name
            txt_path = tmp / text_file.name
            ont_path.write_bytes(onto_file.read())
            txt_path.write_bytes(text_file.read())

            # FIX: Read the text content here, while the file is guaranteed to exist.
            text_content = txt_path.read_text(encoding="utf-8")

            status_area = st.empty()

            status_area.write("–°—Ç—ä–ø–∫–∞ 1/3: –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –ø–æ–≤—ä—Ä—Ö–Ω–æ—Å—Ç–Ω–∏ —Ñ–æ—Ä–º–∏ –æ—Ç –æ–Ω—Ç–æ–ª–æ–≥–∏—è—Ç–∞...")
            csv_path = tmp / "surface_forms.csv"
            extract_forms(ont_path, csv_path)

            status_area.write("–°—Ç—ä–ø–∫–∞ 2/3: –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ FAISS –∏–Ω–¥–µ–∫—Å –æ—Ç —Ñ–æ—Ä–º–∏—Ç–µ...")
            idx_path, lbl_path = build_index(
                csv_path, out_dir=tmp,
                embed_endpoint="http://localhost:1234/v1/embeddings",
                embed_model="mistral-embed", # NOTE: Change if your model name is different
            )

            status_area.write("–°—Ç—ä–ø–∫–∞ 3/3: –ê–Ω–æ—Ç–∏—Ä–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç–∞ —Å LLM –¥–∏—Å–∞–º–±–∏–≥—É–∞—Ü–∏—è...")
            matches = annotate_document(
                txt_path, idx_path, lbl_path,
                ontology_path=ont_path,
                embed_endpoint="http://localhost:1234/v1/embeddings",
                chat_endpoint="http://localhost:1234/v1/chat/completions",
                chat_model="mistral", # NOTE: Change if your model name is different
                top_k=top_k,
                threshold=default_thresh,
                single_word_threshold=single_word_thresh
            )
            status_area.empty()

    # Store results in session state for interactive use
    st.session_state["text_content"] = text_content
    st.session_state["matches"] = matches
    # Create a dictionary to hold the state of checkboxes for the GOLD standard
    st.session_state["gold"] = {
        (m["surface_form"], m["start"], m["end"], m["uri"]): True
        for m in matches
    }
    st.rerun()
    
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4. Display Results and Interaction ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if "matches" in st.session_state:
    matches = st.session_state["matches"]
    st.success(f"‚úÖ –ù–∞–º–µ—Ä–µ–Ω–∏ {len(matches)} —Å—ä–≤–ø–∞–¥–µ–Ω–∏—è")
    
    # Display results in a dataframe
    st.dataframe(matches, use_container_width=True)

    st.subheader("‚úèÔ∏è –†—ä—á–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ (‚úî –ø—Ä–∏–µ–º–∏ / ‚ùå –æ—Ç—Ö–≤—ä—Ä–ª–∏)")
    # Create checkboxes for user validation
    for i, m in enumerate(matches):
        key = (m["surface_form"], m["start"], m["end"], m["uri"])
        st.session_state["gold"][key] = st.checkbox(
            f'**{m["surface_form"]}** @ ({m["start"]}:{m["end"]}) ‚Üí *{m["label"]}* (Score: {m["score"]:.2f})',
            value=ss_get("gold", {}).get(key, True),
            key=f'gold_{i}'
        )

    # --- Download Buttons ---
    st.subheader("‚¨áÔ∏è –ò–∑—Ç–µ–≥–ª—è–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏")
    dl_col1, dl_col2, dl_col3 = st.columns(3)

    # AUTO.json (all matches found by the system)
    json_auto = json.dumps(matches, ensure_ascii=False, indent=2)
    dl_col1.download_button("AUTO.json", json_auto,
                            f"matches_auto.json", "application/json")

    # CSV
    if matches:
        csv_header = ",".join(matches[0].keys())
        csv_rows = [",".join(map(str, m.values())) for m in matches]
        csv_lines = "\n".join([csv_header] + csv_rows)
        dl_col2.download_button("matches.csv", csv_lines,
                                f"matches.csv", "text/csv")

    # GOLD.json (only user-accepted matches)
    # Create a mapping from key to full match object for robust lookup
    match_map = { (m["surface_form"], m["start"], m["end"], m["uri"]): m for m in matches }
    gold_matches = [
        match_map[m_key] for m_key, ok in st.session_state.get("gold", {}).items() if ok
    ]
    json_gold = json.dumps(gold_matches, ensure_ascii=False, indent=2)
    dl_col3.download_button("GOLD.json", json_gold,
                            f"matches_gold.json", "application/json")